\chapter{Probabilidad}
\section{Definiciones preliminares}
\paragraph{Experimento aleatorio:}
Es aquel que, bajo las mismas condiciones iniciales, puede presentar varios resultados diferentes sin que pueda predecirse en cada caso el resultado que se obtendrá.
\subparagraph{}
Para que un experimento sea aleatorio debe verificar:
\begin{itemize}
\item Que pueda ser repetido, en las mismas condiciones, un número ilimitado de veces.
\item Se conozca de antemano los posibles resultados del experimento.
\item En cada repetición no es posible conocer el resultado que se obtendrá.
\end{itemize}
\paragraph{Espacio muestral asociado a un experimento aleatorio:}
Es el conjunto formado por todos los posibles resultados del experimento aleatorio. Lo designamos con la letra $E$.
\paragraph{Suceso:} Se denomina así a cada uno de los subconjuntos del espacio muestral.
\subparagraph{}
Existen dos tipos de sucesos según su composición:
\begin{itemize}
\item \textbf{Suceso elemental:} Cada uno de los resultados del experimento.
\item \textbf{Suceso compuesto:} El formado por la unión de sucesos elementales.
\end{itemize}
\paragraph{Suceso seguro:}
Es aquel que se verifica siempre. Designado por $E$.
\paragraph{Suceso imposible:}
Es aquel que no se verifica nunca. Lo designamos por $\phi$.
\paragraph{Espacio de sucesos:}
Es el conjunto formado por todos los sucesos compuestos, incluido el suceso imposible. Se designa por $\beta$.


\section{Operaciones con sucesos}
Sean $A,B \in \beta$:
\paragraph{Suceso unión:} Es el suceso que resulta cuando ocurre $A$, ocurre $B$ o ambos a la vez. Lo designamos por $A \cup B$.
\paragraph{Suceso intersección:} Es el suceso que resulta cuando ocurren $A$ y $B$ a la vez. Lo designamos con $A \cap B$.
\paragraph{Inclusión de sucesos:} Diremos que $A \subset B$ si siempre que ocurre $A$ ocurre $B$. Si $A \subset B$, entonces $A \cap B = A$ y $A \cup B = B$.
\paragraph{Igualdad de sucesos:}Diremos que $A = B$ si $A \subset B$ y $B \subset A$.
\paragraph{Sucesos incompatibles:} Dos sucesos son incompatibles cuando al verificarse uno, no puede hacerlo el otro, su intersección es $\phi$.
\paragraph{Suceso contrario:} El suceso contrario de $A$ es el que se verifica cuando no lo hace $A$. Se verifica que $A \cap \overline{A} = \phi$ y $A \cup \overline{A} = E$.
\paragraph{Suceso diferencia:} Se designa por $B - A$. Es el formado por todos los sucesos elementales que pertenecen a $B$ pero no a $A$. Se verifica que $B - A = B \cap \overline{A}$. Además $\overline{A} = E - A$.


\section{Leyes de Morgan}
Sean $A, B \in \beta$:
\begin{itemize}
\item $\overline{A \cup B} = \overline{A} \cap \overline{B}$
\item $\overline{A \cap B} = \overline{A} \cup \overline{B}$
\end{itemize}


\section{Álgebra de sucesos}
Todas las operaciones anteriores se pueden realizar porque $\beta$ tiene estructura de álgebra (es un álgebra de Boole) cuando $E$ es finito o de $\sigma$-álgebra cuando $E$ es infinito.


\section{Definición axiomática de probabilidad}
Diremos que una aplicación $P: \beta \rightarrow \mathbb{R}$ es una probabilidad si verifica:
\begin{itemize}
\item[1.]Si $A \in \beta, P(A) \geq 0$.
\item[2.]$P(E) = 1$.
\item[3.]Si $A_{1},A_{2},...,A_{n} \in \beta$ son sucesos incompatibles dos a dos, entonces $P(A_{1} \cup A_{2} \cup ... \cup A_{n}) = P(A_{1}) + P(A_{2}) + ... + P(A_{n})$.
\end{itemize}
La terna $(E,\beta,P)$ se denomina \textbf{espacio probabilístico}.

\subsection{Consecuencias de los axiomas}
\begin{itemize}
\item[1.]Si $A \in \beta, P(\overline{A}) = 1 - P(A)$.
\item[2.]$P(\phi)=0$.
\item[3.]Si $A,B \in \beta$ son tales que $B \subset A$, entonces:
\begin{itemize}
\item[1.]$P(B) \leq P(A)$.
\item[2.]$P(A-B)=P(A)-P(B)$.
\end{itemize}
\item[4.]Si $A \in \beta, P(A)\leq1$.
\item[5.]Si $A, B \in \beta$ son compatibles, es decir, existe $A \cap B \neq \phi$, entonces $P(A \cup B)=P(A)+P(B)-P(A \cap B)$.
\item[6.]Regla de Laplace: Sean $A_{1},...,A_{n}$ sucesos elementales, es decir, incompatibles dos a dos y tales que $A_{1} \cup ... \cup A_{n} = E$. Supongamos además que $P(A_{1})=...=P(A_{n})$. Entonces para todo $A \in \beta$:
\[P(A)= \frac{Casos\:favorables\:al\:suceso\:A}{Casos\:posibles}\]
\end{itemize}

\section{Probabilidad condicionada}
Sean $A,B \in \beta$ tales que $P(A)>0$. Se llama probabilidad de $B$ condicionada por $A$ y se escribe $P(B|A)$ a la probabilidad de que ocurra $B$ sabiendo que se ha verificado $A$. Se verifica que:
\[P(B|A)=\frac{P(B \cap A)}{P(A)}\]

Análogamente, si $P(B)>0$, se define la probabilidad del suceso $A$ condicionada por $B$ a:
\[P(A|B)=\frac{P(A \cap B)}{P(B)}\]

El espacio de probabilidad condicionada es un espacio probabilístico, luego se verifican todos los axiomas y todas las propiedades asociadas a la probabilidad.

\section{Independencia de sucesos}
Sean $A,B \in \beta$.
\begin{itemize}
\item Diremos que $A$ es independiente de $B$ si $P(A|B)=P(A)$.
\item Diremos que $B$ es independiente de $A$ si $P(B|A)=P(B)$.
\item Si $A$ es independiente de $B$, entonces $B$ es independiente de $A$ y podemos hablar de sucesos independientes.
\end{itemize}
\subsection{Intersección de sucesos independientes}
Sean $A,B \in \beta$. A y B son independientes si y solo si:
\[P(A \cap B)=P(A)*P(B)\]
\subsection{Independencia de sucesos contrarios}
Sean $A,B \in \beta$ sucesos independientes. Entonces:
\begin{itemize}
\item $A$ y $\overline{B}$ son independientes.
\item $\overline{A}$ y $B$ son independientes.
\item $\overline{A}$ y $\overline{B}$ son independientes.
\end{itemize}

\section{Probabilidad compuesta}
Tenemos un conjunto de sucesos $A_{1},...,A_{n} \in \beta$ tales que $P(A_{1} \cap ... \cap A_{n})>0$. Entonces:
\[P(A_{1} \cap ... \cap A_{n}) = P(A_{1})*P(A_{2}|A_{1})*...*P(A_{n}|A_{1} \cap ... \cap A_{n-1})\]

\subsection{Teorema de la probabilidad total}
Sean $A_{1},...,A_{n} \in \beta$ incompatibles dos a dos y tales que $A_{1} \cup ... \cup A_{n} = E$. Sea $B \in \beta$ un suceso cualquiera y supongamos conocidas $P(A_{i})>0$ y $P(B|A_{i})$. Entonces:
\[P(B) = \sum_{i=1}^{n} P(B|A_{i})*P(A_{i})\]

\subsection{Teorema de Bayes}
Sean $A_{1},...,A_{n} \in \beta$ incompatibles dos a dos y tales que $A_{1} \cup ... \cup A_{n} = E$. Sea $B \in \beta$ un suceso cualquiera y supongamos conocidas $P(A_{i})>0$ y $P(B|A_{i})$. Entonces, fijado $k \in {1,2,...,n}$, se verifica que:
\[P(A_{k}|B) = \frac{P(B|A_{k})*P(A_{k})}{ \sum_{i=1}^{n} P(B|A_{i})*P(A_{i})}\]